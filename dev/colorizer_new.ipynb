{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Conv2D, Conv2DTranspose, UpSampling2D\n",
    "from keras.layers import Activation, Dense, Dropout, Flatten, InputLayer\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.callbacks import TensorBoard\n",
    "from keras.models import Sequential\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "from skimage.color import rgb2lab, lab2rgb, rgb2gray\n",
    "from skimage.io import imsave\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "import tensorflow as tf\n",
    "\n",
    "import PIL\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# resizeing images\n",
    "f = r'C:\\Users\\setr7\\Documents\\Jupyter_notebook\\Untitled Folder\\Images_new\\resize'\n",
    "for file in os.listdir(f):\n",
    "    f_img = f+\"/\"+file\n",
    "    img = Image.open(f_img)\n",
    "    img = img.resize((256,256))\n",
    "    img.save(f_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get images\n",
    "#Images_new/Train/\n",
    "images = []\n",
    "for filename in os.listdir('Images_new/resize/'):\n",
    "    images.append(img_to_array(load_img('Images_new/resize/'+filename)))\n",
    "images = np.array(images, dtype=float)\n",
    "\n",
    "# Set up train and test data\n",
    "split = int(0.95*len(images))\n",
    "images_train = images[:split]\n",
    "\n",
    "# 1.0/255 -> 24 bit RGB color, [0-255] for each color channel -> 16.7m combinations -> human can recognize 2-10m \n",
    "images_train = 1.0/255*images_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(InputLayer(input_shape=(256, 256, 1)))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu', padding='same', strides=2))\n",
    "model.add(Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
    "model.add(Conv2D(128, (3, 3), activation='relu', padding='same', strides=2))\n",
    "model.add(Conv2D(256, (3, 3), activation='relu', padding='same'))\n",
    "model.add(Conv2D(256, (3, 3), activation='relu', padding='same', strides=2))\n",
    "model.add(Conv2D(512, (3, 3), activation='relu', padding='same'))\n",
    "model.add(Conv2D(256, (3, 3), activation='relu', padding='same'))\n",
    "model.add(Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
    "model.add(UpSampling2D((2, 2)))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
    "model.add(UpSampling2D((2, 2)))\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', padding='same'))\n",
    "model.add(Conv2D(2, (3, 3), activation='tanh', padding='same'))\n",
    "model.add(UpSampling2D((2, 2)))\n",
    "model.compile(optimizer='rmsprop', loss='mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "10/10 [==============================] - 24s 2s/step - loss: 0.8926\n",
      "Epoch 2/100\n",
      "10/10 [==============================] - 27s 3s/step - loss: 0.3983\n",
      "Epoch 3/100\n",
      "10/10 [==============================] - 26s 3s/step - loss: 0.0123\n",
      "Epoch 4/100\n",
      "10/10 [==============================] - 29s 3s/step - loss: 0.0145\n",
      "Epoch 5/100\n",
      "10/10 [==============================] - 30s 3s/step - loss: 0.0135\n",
      "Epoch 6/100\n",
      "10/10 [==============================] - 30s 3s/step - loss: 0.0153\n",
      "Epoch 7/100\n",
      "10/10 [==============================] - 30s 3s/step - loss: 0.0139\n",
      "Epoch 8/100\n",
      "10/10 [==============================] - 30s 3s/step - loss: 0.0130\n",
      "Epoch 9/100\n",
      "10/10 [==============================] - 30s 3s/step - loss: 0.0156\n",
      "Epoch 10/100\n",
      "10/10 [==============================] - 30s 3s/step - loss: 0.0152\n",
      "Epoch 11/100\n",
      "10/10 [==============================] - 32s 3s/step - loss: 0.0121\n",
      "Epoch 12/100\n",
      "10/10 [==============================] - 32s 3s/step - loss: 0.0130\n",
      "Epoch 13/100\n",
      "10/10 [==============================] - 33s 3s/step - loss: 0.0119\n",
      "Epoch 14/100\n",
      "10/10 [==============================] - 34s 3s/step - loss: 0.0172\n",
      "Epoch 15/100\n",
      "10/10 [==============================] - 33s 3s/step - loss: 0.0123\n",
      "Epoch 16/100\n",
      "10/10 [==============================] - 34s 3s/step - loss: 0.0142\n",
      "Epoch 17/100\n",
      "10/10 [==============================] - 32s 3s/step - loss: 0.0137\n",
      "Epoch 18/100\n",
      "10/10 [==============================] - 33s 3s/step - loss: 0.0123\n",
      "Epoch 19/100\n",
      "10/10 [==============================] - 34s 3s/step - loss: 0.0154\n",
      "Epoch 20/100\n",
      "10/10 [==============================] - 34s 3s/step - loss: 0.0151\n",
      "Epoch 21/100\n",
      "10/10 [==============================] - 39s 4s/step - loss: 0.0152\n",
      "Epoch 22/100\n",
      "10/10 [==============================] - 42s 4s/step - loss: 0.0173\n",
      "Epoch 23/100\n",
      "10/10 [==============================] - 40s 4s/step - loss: 0.0129\n",
      "Epoch 24/100\n",
      "10/10 [==============================] - 40s 4s/step - loss: 0.0128\n",
      "Epoch 25/100\n",
      "10/10 [==============================] - 38s 4s/step - loss: 0.0125\n",
      "Epoch 26/100\n",
      "10/10 [==============================] - 36s 4s/step - loss: 0.0118\n",
      "Epoch 27/100\n",
      "10/10 [==============================] - 36s 4s/step - loss: 0.0122\n",
      "Epoch 28/100\n",
      "10/10 [==============================] - 36s 4s/step - loss: 0.0151\n",
      "Epoch 29/100\n",
      "10/10 [==============================] - 35s 3s/step - loss: 0.0135\n",
      "Epoch 30/100\n",
      "10/10 [==============================] - 37s 4s/step - loss: 0.0154\n",
      "Epoch 31/100\n",
      "10/10 [==============================] - 36s 4s/step - loss: 0.0584\n",
      "Epoch 32/100\n",
      "10/10 [==============================] - 36s 4s/step - loss: 0.0130\n",
      "Epoch 33/100\n",
      "10/10 [==============================] - 36s 4s/step - loss: 0.0152\n",
      "Epoch 34/100\n",
      "10/10 [==============================] - 35s 3s/step - loss: 0.0157\n",
      "Epoch 35/100\n",
      "10/10 [==============================] - 36s 4s/step - loss: 0.0155\n",
      "Epoch 36/100\n",
      "10/10 [==============================] - 35s 4s/step - loss: 0.0118\n",
      "Epoch 37/100\n",
      "10/10 [==============================] - 37s 4s/step - loss: 0.0156\n",
      "Epoch 38/100\n",
      "10/10 [==============================] - 36s 4s/step - loss: 0.0142\n",
      "Epoch 39/100\n",
      "10/10 [==============================] - 37s 4s/step - loss: 0.0177\n",
      "Epoch 40/100\n",
      "10/10 [==============================] - 36s 4s/step - loss: 0.0140\n",
      "Epoch 41/100\n",
      "10/10 [==============================] - 36s 4s/step - loss: 0.0127\n",
      "Epoch 42/100\n",
      "10/10 [==============================] - 37s 4s/step - loss: 0.0174\n",
      "Epoch 43/100\n",
      "10/10 [==============================] - 38s 4s/step - loss: 0.0128\n",
      "Epoch 44/100\n",
      "10/10 [==============================] - 36s 4s/step - loss: 0.0132\n",
      "Epoch 45/100\n",
      "10/10 [==============================] - 36s 4s/step - loss: 0.0124\n",
      "Epoch 46/100\n",
      "10/10 [==============================] - 36s 4s/step - loss: 0.0134\n",
      "Epoch 47/100\n",
      "10/10 [==============================] - 38s 4s/step - loss: 0.0109\n",
      "Epoch 48/100\n",
      "10/10 [==============================] - 37s 4s/step - loss: 0.0168\n",
      "Epoch 49/100\n",
      "10/10 [==============================] - 37s 4s/step - loss: 0.0137\n",
      "Epoch 50/100\n",
      "10/10 [==============================] - 37s 4s/step - loss: 0.0143\n",
      "Epoch 51/100\n",
      "10/10 [==============================] - 36s 4s/step - loss: 0.0123\n",
      "Epoch 52/100\n",
      "10/10 [==============================] - 37s 4s/step - loss: 0.0177\n",
      "Epoch 53/100\n",
      "10/10 [==============================] - 37s 4s/step - loss: 0.0133\n",
      "Epoch 54/100\n",
      "10/10 [==============================] - 37s 4s/step - loss: 0.0139\n",
      "Epoch 55/100\n",
      "10/10 [==============================] - 38s 4s/step - loss: 0.0122\n",
      "Epoch 56/100\n",
      "10/10 [==============================] - 38s 4s/step - loss: 0.0111\n",
      "Epoch 57/100\n",
      "10/10 [==============================] - 37s 4s/step - loss: 0.0180\n",
      "Epoch 58/100\n",
      "10/10 [==============================] - 38s 4s/step - loss: 0.0145\n",
      "Epoch 59/100\n",
      "10/10 [==============================] - 37s 4s/step - loss: 0.0137\n",
      "Epoch 60/100\n",
      "10/10 [==============================] - 37s 4s/step - loss: 0.0140\n",
      "Epoch 61/100\n",
      "10/10 [==============================] - 37s 4s/step - loss: 0.0127\n",
      "Epoch 62/100\n",
      "10/10 [==============================] - 39s 4s/step - loss: 0.0135\n",
      "Epoch 63/100\n",
      "10/10 [==============================] - 39s 4s/step - loss: 0.0132\n",
      "Epoch 64/100\n",
      "10/10 [==============================] - 39s 4s/step - loss: 0.0139\n",
      "Epoch 65/100\n",
      "10/10 [==============================] - 37s 4s/step - loss: 0.0167\n",
      "Epoch 66/100\n",
      "10/10 [==============================] - 37s 4s/step - loss: 0.0150\n",
      "Epoch 67/100\n",
      "10/10 [==============================] - 37s 4s/step - loss: 0.0109\n",
      "Epoch 68/100\n",
      "10/10 [==============================] - 36s 4s/step - loss: 0.0189\n",
      "Epoch 69/100\n",
      "10/10 [==============================] - 37s 4s/step - loss: 0.0138\n",
      "Epoch 70/100\n",
      "10/10 [==============================] - 37s 4s/step - loss: 0.0157\n",
      "Epoch 71/100\n",
      "10/10 [==============================] - 34s 3s/step - loss: 0.0131\n",
      "Epoch 72/100\n",
      "10/10 [==============================] - 27s 3s/step - loss: 0.0132\n",
      "Epoch 73/100\n",
      "10/10 [==============================] - 26s 3s/step - loss: 0.0123\n",
      "Epoch 74/100\n",
      "10/10 [==============================] - 26s 3s/step - loss: 0.0142\n",
      "Epoch 75/100\n",
      "10/10 [==============================] - 27s 3s/step - loss: 0.0135\n",
      "Epoch 76/100\n",
      "10/10 [==============================] - 26s 3s/step - loss: 0.0150\n",
      "Epoch 77/100\n",
      "10/10 [==============================] - 27s 3s/step - loss: 0.0141\n",
      "Epoch 78/100\n",
      "10/10 [==============================] - 26s 3s/step - loss: 0.0113\n",
      "Epoch 79/100\n",
      "10/10 [==============================] - 26s 3s/step - loss: 0.0107\n",
      "Epoch 80/100\n",
      "10/10 [==============================] - 27s 3s/step - loss: 0.0113\n",
      "Epoch 81/100\n",
      "10/10 [==============================] - 27s 3s/step - loss: 0.0140\n",
      "Epoch 82/100\n",
      "10/10 [==============================] - 28s 3s/step - loss: 0.0150\n",
      "Epoch 83/100\n",
      "10/10 [==============================] - 31s 3s/step - loss: 0.0138\n",
      "Epoch 84/100\n",
      "10/10 [==============================] - 33s 3s/step - loss: 0.0150\n",
      "Epoch 85/100\n",
      "10/10 [==============================] - 31s 3s/step - loss: 0.0148\n",
      "Epoch 86/100\n",
      "10/10 [==============================] - 33s 3s/step - loss: 0.0133\n",
      "Epoch 87/100\n",
      "10/10 [==============================] - 33s 3s/step - loss: 0.0121\n",
      "Epoch 88/100\n",
      "10/10 [==============================] - 34s 3s/step - loss: 0.0148\n",
      "Epoch 89/100\n",
      "10/10 [==============================] - 36s 4s/step - loss: 0.0145\n",
      "Epoch 90/100\n",
      "10/10 [==============================] - 37s 4s/step - loss: 0.0115\n",
      "Epoch 91/100\n",
      "10/10 [==============================] - 37s 4s/step - loss: 0.0142\n",
      "Epoch 92/100\n",
      "10/10 [==============================] - 36s 4s/step - loss: 0.0136\n",
      "Epoch 93/100\n",
      "10/10 [==============================] - 36s 4s/step - loss: 0.0143\n",
      "Epoch 94/100\n",
      "10/10 [==============================] - 37s 4s/step - loss: 0.0213\n",
      "Epoch 95/100\n",
      "10/10 [==============================] - 36s 4s/step - loss: 0.0153\n",
      "Epoch 96/100\n",
      "10/10 [==============================] - 36s 4s/step - loss: 0.0123\n",
      "Epoch 97/100\n",
      "10/10 [==============================] - 37s 4s/step - loss: 0.0103\n",
      "Epoch 98/100\n",
      "10/10 [==============================] - 37s 4s/step - loss: 0.0137\n",
      "Epoch 99/100\n",
      "10/10 [==============================] - 36s 4s/step - loss: 0.0120\n",
      "Epoch 100/100\n",
      "10/10 [==============================] - 36s 4s/step - loss: 0.0126\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x23734f17550>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Image datagenerator, adjust setting for img\n",
    "datagen = ImageDataGenerator(\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        rotation_range=20,\n",
    "        horizontal_flip=True)\n",
    "\n",
    "# Generate training data\n",
    "batch_size = 10\n",
    "def image_a_b_gen(batch_size):\n",
    "    for batch in datagen.flow(images_train, batch_size=batch_size):\n",
    "        lab_batch = rgb2lab(batch)\n",
    "        # extract b/w layer for x_batch, two color layers for y_batch\n",
    "        X_batch = lab_batch[:,:,:,0]\n",
    "        Y_batch = lab_batch[:,:,:,1:] / 128\n",
    "        yield (X_batch.reshape(X_batch.shape+(1,)), Y_batch)\n",
    "\n",
    "# Train model  -- tensorboard not required ??    \n",
    "tensorboard = TensorBoard(log_dir=\"output/first_run\")\n",
    "#callbacks=[tensorboard]\n",
    "model.fit_generator(image_a_b_gen(batch_size), epochs=100, steps_per_epoch=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model\n",
    "model_json = model.to_json()\n",
    "with open(\"modelNew_resized2.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "model.save_weights(\"modelNew_resized2.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90/90 [==============================] - 5s 54ms/step\n",
      "0.007139213693638642\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Test images \n",
    "# Lab color, L -> grayscale layer, a b -> color layers (green-red, blue-yellow)\n",
    "Xtest = rgb2lab(1.0/255*images[split:])[:,:,:,0]  # [:,:,:,0] -> select grayscale layer\n",
    "Xtest = Xtest.reshape(Xtest.shape+(1,))\n",
    "Ytest = rgb2lab(1.0/255*images[split:])[:,:,:,1:] # [:,:,:,1] -> select color layer\n",
    "\n",
    "# ab spectrum [-128,128] .. divide by 128 to get [-1,1]\n",
    "Ytest = Ytest / 128\n",
    "print(model.evaluate(Xtest, Ytest, batch_size=batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n"
     ]
    }
   ],
   "source": [
    "# colorizer section \n",
    "# init array and add img to color\n",
    "images_to_color = []\n",
    "for filename in os.listdir('Images_new/Test/'):\n",
    "    images_to_color.append(img_to_array(load_img('images_new/Test/'+filename)))\n",
    "\n",
    "# covert color space, reshape img\n",
    "images_to_color = np.array(images_to_color, dtype=float)\n",
    "images_to_color = rgb2lab(1.0/255*images_to_color)[:,:,:,0]\n",
    "images_to_color = images_to_color.reshape(images_to_color.shape+(1,))\n",
    "\n",
    "# Test model with predict function\n",
    "output = model.predict(images_to_color)\n",
    "\n",
    "# covert color value back from [-1,1] to [-128,128] which is Lab color spectrum\n",
    "output = output * 128\n",
    "\n",
    "# Output colorizations\n",
    "for i in range(len(output)):\n",
    "    \n",
    "    # make empty 256x256 with 3 layera\n",
    "    cur = np.zeros((256, 256, 3))\n",
    "    # copy grayscale layer to new obj\n",
    "    cur[:,:,0] = images_to_color[i][:,:,0]\n",
    "    # copy color layer to new obj\n",
    "    cur[:,:,1:] = output[i]\n",
    "    # save img in directory\n",
    "    imsave(\"Images_new/Result/img_\"+str(i)+\".png\", lab2rgb(cur))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
